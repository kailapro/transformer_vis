{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Transformer Architecture Visualization\n",
    "\n",
    "This notebook demonstrates the interactive visualization capabilities.\n",
    "\n",
    "**Features:**\n",
    "- Hover over attention blocks to see individual heads\n",
    "- Hover over MLP blocks to see the expansion/contraction\n",
    "- Residual stream flows on the left with blocks branching off\n",
    "- Shows the \"+\" operation where outputs are added back to residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "from transformer_viz import visualize, InteractiveTransformerViz, VisualizationConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Visualization\n",
    "\n",
    "The simplest way to visualize a model - just call `visualize()` with a model name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(\"gpt2\", max_layers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different Models\n",
    "\n",
    "Visualize other architectures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pythia - smaller model\n",
    "visualize(\"pythia-70m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT-2 Medium - larger model (showing 3 layers)\n",
    "visualize(\"gpt2-medium\", max_layers=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Architecture\n",
    "\n",
    "Define your own model configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = {\n",
    "    \"n_layers\": 4,\n",
    "    \"d_model\": 256,\n",
    "    \"n_heads\": 4,\n",
    "    \"d_head\": 64,\n",
    "    \"d_mlp\": 1024,\n",
    "    \"d_vocab\": 10000,\n",
    "    \"model_name\": \"My Tiny Transformer\"\n",
    "}\n",
    "\n",
    "visualize(my_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With TransformerLens Model\n",
    "\n",
    "Works directly with TransformerLens `HookedTransformer` models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if you have transformer-lens installed:\n",
    "#\n",
    "# from transformer_lens import HookedTransformer\n",
    "# \n",
    "# model = HookedTransformer.from_pretrained(\"gpt2-small\")\n",
    "# visualize(model, max_layers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Colors\n",
    "\n",
    "Customize the visualization style:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purple and green theme\n",
    "custom_config = VisualizationConfig(\n",
    "    attention_block_color=\"#6C5CE7\",\n",
    "    mlp_block_color=\"#00B894\",\n",
    "    embedding_color=\"#E17055\",\n",
    "    unembedding_color=\"#0984E3\",\n",
    "    attention_head_colors=[\n",
    "        \"#a29bfe\", \"#74b9ff\", \"#81ecec\", \"#55efc4\",\n",
    "        \"#ffeaa7\", \"#fab1a0\", \"#fd79a8\", \"#e17055\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "visualize(\"gpt2\", max_layers=3, config=custom_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention-Only Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with no MLP (attention only)\n",
    "attn_only = {\n",
    "    \"n_layers\": 2,\n",
    "    \"d_model\": 512,\n",
    "    \"n_heads\": 8,\n",
    "    \"d_head\": 64,\n",
    "    \"d_mlp\": 0,  # No MLP!\n",
    "    \"d_vocab\": 50257,\n",
    "    \"model_name\": \"Attention-Only 2L\"\n",
    "}\n",
    "\n",
    "visualize(attn_only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save as HTML\n",
    "\n",
    "Save the interactive visualization to share:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = InteractiveTransformerViz()\n",
    "viz.from_pretrained(\"gpt2\")\n",
    "viz.render(max_layers=4)\n",
    "viz.save_html(\"gpt2_interactive.html\")\n",
    "print(\"Saved to gpt2_interactive.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
